{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# automatically reload edited modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import os\n",
    "import yaml\n",
    "import imp\n",
    "import pprint\n",
    "import json\n",
    "from argparse import ArgumentParser\n",
    "import numpy as np\n",
    "import torch\n",
    "from cl.data import *\n",
    "#from train import train\n",
    "from cl.model import MLP\n",
    "import utils\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-16 07:27:44,386 DEBUG Loaded backend module://ipykernel.pylab.backend_inline version unknown.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import image captioning model\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy plotting (could have graph of bleu, meteor, cider ...)\n",
    "def plot_test_acc(plot_handles):\n",
    "    plt.legend(handles=plot_handles, loc=\"center right\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Test Accuracy\")\n",
    "    plt.ylim(0,1)\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s %(levelname)s %(message)s',\n",
    "                    level=logging.DEBUG,\n",
    "                    stream=sys.stdout)\n",
    "\n",
    "def make_paths_absolute(dir_, cfg):\n",
    "    \"\"\"\n",
    "    Make all values for keys ending with `_path` absolute to dir_.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dir_ : str\n",
    "    cfg : dict\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cfg : dict\n",
    "    \"\"\"\n",
    "    for key in cfg.keys():\n",
    "        if type(cfg[key]) is dict:\n",
    "            cfg[key] = make_paths_absolute(dir_, cfg[key])\n",
    "    return cfg\n",
    "\n",
    "def load_and_print_cfg(yaml_filepath):\n",
    "    \"\"\"\n",
    "    Load and print a YAML configuration file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    yaml_filepath : str\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cfg : dict\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read YAML experiment definition file\n",
    "    with open(yaml_filepath, 'r') as stream:\n",
    "        cfg = yaml.load(stream)\n",
    "    cfg = make_paths_absolute(os.path.dirname(yaml_filepath), cfg)\n",
    "\n",
    "    # Print the configuration - just to make sure that you loaded what you\n",
    "    # wanted to load\n",
    "    pp = pprint.PrettyPrinter(indent=4)\n",
    "    pp.pprint(cfg)\n",
    "\n",
    "    # Here is an example how you load modules of which you put the path in the\n",
    "    # configuration. Use this for configuring the model you use, for dataset\n",
    "    # loading, ...\n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'dataset': {   'data_folder': 'caption data',\n",
      "                   'data_name': 'coco_5_cap_per_img_5_min_word_freq'},\n",
      "    'evaluate': {'augmentation_factor': 32, 'batch_size': 1000},\n",
      "    'model': None,\n",
      "    'optimizer': {'lr': '1e-1', 'weight_decay': 0},\n",
      "    'train': {   'batch_size': 128,\n",
      "                 'epochs_per_task': 3,\n",
      "                 'fisher_estimation_sample_size': 1024,\n",
      "                 'hidden_dropout_prob': 0.5,\n",
      "                 'hidden_layer_num': 2,\n",
      "                 'hidden_size': 400,\n",
      "                 'input_dropout_prob': 0.2,\n",
      "                 'lamda': 40,\n",
      "                 'task_number': 3,\n",
      "                 'test_size': 1024}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dexter/miniconda3/envs/advanced_ml/lib/python3.5/site-packages/ipykernel_launcher.py:38: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n"
     ]
    }
   ],
   "source": [
    "# First we solve the configuration problem\n",
    "cfg = load_and_print_cfg(\"sat_cl.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "global best_bleu4, epochs_since_improvement, checkpoint, start_epoch, fine_tune_encoder, data_name, word_map\n",
    "\n",
    "# Read word map\n",
    "word_map_file = os.path.join(cfg['dataset']['data_folder'], 'WORDMAP_' + cfg['dataset']['data_name'] + '.json')\n",
    "with open(word_map_file, 'r') as j:\n",
    "    word_map = json.load(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second we sove the data loading problem\n",
    "# Ignore using checkpoint\n",
    "\n",
    "# Import modules for Show-attend-and-tell\n",
    "import time\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from models import Encoder, DecoderWithAttention\n",
    "from datasets import *\n",
    "from utils import *\n",
    "from nltk.translate.bleu_score import corpus_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramteres for Image Captioning system, should put them in config file later\n",
    "\n",
    "# Model parameters\n",
    "emb_dim = 512  # dimension of word embeddings\n",
    "attention_dim = 512  # dimension of attention linear layers\n",
    "decoder_dim = 512  # dimension of decoder RNN\n",
    "dropout = 0.5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # sets device for model and PyTorch tensors\n",
    "cudnn.benchmark = True  # set to true only if inputs to model are fixed size; otherwise lot of computational overhead\n",
    "\n",
    "# Training parameters\n",
    "start_epoch = 0\n",
    "epochs = 1  # number of epochs to train for (if early stopping is not triggered)\n",
    "epochs_since_improvement = 0  # keeps track of number of epochs since there's been an improvement in validation BLEU\n",
    "batch_size = 32\n",
    "workers = 1  # for data-loading; right now, only 1 works with h5py\n",
    "encoder_lr = 1e-4  # learning rate for encoder if fine-tuning\n",
    "decoder_lr = 4e-4  # learning rate for decoder\n",
    "grad_clip = 5.  # clip gradients at an absolute value of\n",
    "alpha_c = 1.  # regularization parameter for 'doubly stochastic attention', as in the paper\n",
    "best_bleu4 = 0.  # BLEU-4 score right now\n",
    "print_freq = 100  # print training/validation stats every __ batches\n",
    "fine_tune_encoder = False  # fine-tune encoder?\n",
    "checkpoint = None  # path to checkpoint, None if none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = DecoderWithAttention(attention_dim=attention_dim,\n",
    "                               embed_dim=emb_dim,\n",
    "                               decoder_dim=decoder_dim,\n",
    "                               vocab_size=len(word_map),\n",
    "                               dropout=dropout)\n",
    "decoder_optimizer = torch.optim.Adam(params=filter(lambda p: p.requires_grad, decoder.parameters()),\n",
    "                                     lr=decoder_lr)\n",
    "encoder = Encoder()\n",
    "encoder.fine_tune(fine_tune_encoder)\n",
    "encoder_optimizer = torch.optim.Adam(params=filter(lambda p: p.requires_grad, encoder.parameters()),\n",
    "                                     lr=encoder_lr) if fine_tune_encoder else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move to GPU, if available, equivalent to mlp.cuda() in EWC implementation\n",
    "decoder = decoder.to(device)\n",
    "encoder = encoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "# Custom dataloaders\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.utils.data.dataloader.DataLoader'> <class 'torch.utils.data.dataloader.DataLoader'> <class 'torchvision.transforms.transforms.Normalize'> <class 'torch.nn.modules.loss.CrossEntropyLoss'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_loader), type(train_loader), type(normalize), type(criterion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([106012, 181293, 118277, ..., 180420, 157178,  47879]), array([ 99834, 123478, 141323, ...,  49483,  53492,  51708]), array([ 72837,  30020,  47935, ..., 165583, 156438,  32777])]\n",
      "(3, 196608)\n"
     ]
    }
   ],
   "source": [
    "# generate 3 different dataset for 3 tasks\n",
    "permutations = [\n",
    "    np.random.permutation((DATASET_CONFIGS['coco']['size']**2)*DATASET_CONFIGS['coco']['channels']) for\n",
    "    _ in range(cfg['train']['task_number'])\n",
    "]\n",
    "print(permutations)\n",
    "print(np.shape(permutations))\n",
    "\n",
    "# prepare ms-coco datasets.\n",
    "train_datasets = [\n",
    "    get_dataset('coco', permutation=p) for p in permutations\n",
    "]\n",
    "test_datasets = [\n",
    "    get_dataset('coco', train=False, permutation=p) for p in permutations\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train the model\n",
    "def train(train_datasets, test_datasets, encoder, decoder, epochs_per_task, batch_size, test_size, consolidate,\n",
    "          fisher_estimation_sample_size, lr, weight_decay, loss_log_interval, eval_log_interval, cuda,\n",
    "          criterion, encoder_optimizer, decoder_optimizer, epoch):\n",
    "    \"\"\"\n",
    "    Performs one epoch's training.\n",
    "\n",
    "    :param \n",
    "    :param \n",
    "    :param \n",
    "    :param \n",
    "    :param \n",
    "    :param \n",
    "    :param \n",
    "    \"\"\"\n",
    "\n",
    "    decoder.train()  # train mode (dropout and batchnorm is used)\n",
    "    encoder.train()\n",
    "\n",
    "    batch_time = AverageMeter()  # forward prop. + back prop. time\n",
    "    data_time = AverageMeter()  # data loading time\n",
    "    losses = AverageMeter()  # loss (per word decoded)\n",
    "    top5accs = AverageMeter()  # top5 accuracy\n",
    "\n",
    "    start = time.time()\n",
    "    # loop over multiple tasks\n",
    "    for task, train_dataset in enumerate(train_datasets, 1):\n",
    "        \n",
    "        # Dang xem xet train_loader va val_loader da dung va tuong duong voi data_loader trong ewc chua\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            CaptionDataset(cfg['dataset']['data_folder'], cfg['dataset']['data_name'], 'TRAIN', transform=transforms.Compose([normalize])),\n",
    "            batch_size=batch_size, shuffle=True, num_workers=workers, pin_memory=True)\n",
    "        val_loader = torch.utils.data.DataLoader(\n",
    "            CaptionDataset(cfg['dataset']['data_folder'], cfg['dataset']['data_name'], 'VAL', transform=transforms.Compose([normalize])),\n",
    "            batch_size=batch_size, shuffle=True, num_workers=workers, pin_memory=True)\n",
    "        \n",
    "        # loop over epochs\n",
    "        for epoch in range(start_epoch, epochs):\n",
    "            # Decay learning rate if there is no improvement for 8 consecutive epochs, and terminate training after 20\n",
    "            if epochs_since_improvement == 20:\n",
    "                break\n",
    "            if epochs_since_improvement > 0 and epochs_since_improvement % 8 == 0:\n",
    "                adjust_learning_rate(decoder_optimizer, 0.8)\n",
    "                if fine_tune_encoder:\n",
    "                    adjust_learning_rate(encoder_optimizer, 0.8)\n",
    "            \n",
    "            # loop over batches\n",
    "            for i, (imgs, caps, caplens) in enumerate(train_loader):\n",
    "                data_time.update(time.time() - start)\n",
    "\n",
    "\n",
    "                # Move to GPU, if available\n",
    "                imgs = imgs.to(device)\n",
    "                caps = caps.to(device)\n",
    "                caplens = caplens.to(device)\n",
    "\n",
    "                # Forward prop.\n",
    "                imgs = encoder(imgs)\n",
    "                scores, caps_sorted, decode_lengths, alphas, sort_ind = decoder(imgs, caps, caplens)\n",
    "\n",
    "                # Since we decoded starting with <start>, the targets are all words after <start>, up to <end>\n",
    "                targets = caps_sorted[:, 1:]\n",
    "\n",
    "                # Remove timesteps that we didn't decode at, or are pads\n",
    "                # pack_padded_sequence is an easy trick to do this\n",
    "                scores, _ = pack_padded_sequence(scores, decode_lengths, batch_first=True)\n",
    "                targets, _ = pack_padded_sequence(targets, decode_lengths, batch_first=True)\n",
    "\n",
    "                # Calculate loss\n",
    "                loss = criterion(scores, targets)\n",
    "\n",
    "                # Add doubly stochastic attention regularization\n",
    "                loss += alpha_c * ((1. - alphas.sum(dim=1)) ** 2).mean()\n",
    "\n",
    "                ewc_loss = decoder.ewc_loss(cuda=cuda) + encoder.ewc_loss(cuda=cuda)\n",
    "                ewc_loss.resize_([])\n",
    "                '''\n",
    "                print(decoder.ewc_loss(cuda=cuda), encoder.ewc_loss(cuda=cuda), loss, ewc_loss)\n",
    "                print(type(decoder.ewc_loss(cuda=cuda)), type(encoder.ewc_loss(cuda=cuda)), type(loss), type(ewc_loss))\n",
    "                print(ewc_loss.size())\n",
    "                print(loss.size())\n",
    "                '''\n",
    "                loss +=  ewc_loss\n",
    "\n",
    "                # Back prop.\n",
    "                decoder_optimizer.zero_grad()\n",
    "                if encoder_optimizer is not None:\n",
    "                    encoder_optimizer.zero_grad()\n",
    "                loss.backward() # Convert tensor [1] [0] de ko bi loi\n",
    "\n",
    "                # Clip gradients\n",
    "                if grad_clip is not None:\n",
    "                    clip_gradient(decoder_optimizer, grad_clip)\n",
    "                    if encoder_optimizer is not None:\n",
    "                        clip_gradient(encoder_optimizer, grad_clip)\n",
    "\n",
    "                # Update weights\n",
    "                decoder_optimizer.step()\n",
    "                if encoder_optimizer is not None:\n",
    "                    encoder_optimizer.step()\n",
    "\n",
    "                # Keep track of metrics\n",
    "                top5 = accuracy(scores, targets, 5)\n",
    "                losses.update(loss.item(), sum(decode_lengths)) \n",
    "                top5accs.update(top5, sum(decode_lengths))\n",
    "                batch_time.update(time.time() - start)\n",
    "\n",
    "                start = time.time()\n",
    "\n",
    "                # Print status\n",
    "                if i % print_freq == 0:\n",
    "                    print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                          'Batch Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                          'Data Load Time {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                          'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                          'Top-5 Accuracy {top5.val:.3f} ({top5.avg:.3f})'.format(epoch, i, len(train_loader),\n",
    "                                                                                  batch_time=batch_time,\n",
    "                                                                                  data_time=data_time, loss=losses,\n",
    "                                                                                  top5=top5accs))\n",
    "\n",
    "        if task < len(train_datasets):  \n",
    "            #if consolidate and task < len(train_datasets):\n",
    "            # estimate the fisher information of the parameters and consolidate\n",
    "            # them in the network.\n",
    "            print(\n",
    "                '=> Estimating diagonals of the fisher information matrix...',\n",
    "                flush=True, end='',\n",
    "            )\n",
    "            encoder.consolidate(model.estimate_fisher(\n",
    "                train_dataset, fisher_estimation_sample_size # Working: train_dataset cua ewc tuong ung voi cai nao trong SAT??\n",
    "            ))\n",
    "            decoder.consolidate(model.estimate_fisher(\n",
    "                train_dataset, fisher_estimation_sample_size # Working: train_dataset cua ewc tuong ung voi cai nao trong SAT??\n",
    "            ))\n",
    "            print(' Done!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/17702]\tBatch Time 2.703 (2.703)\tData Load Time 2.486 (2.486)\tLoss 10.0094 (10.0094)\tTop-5 Accuracy 1.408 (1.408)\n",
      "Epoch: [0][100/17702]\tBatch Time 0.221 (0.234)\tData Load Time 0.000 (0.025)\tLoss 6.0695 (6.6234)\tTop-5 Accuracy 39.276 (34.915)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/dexter/miniconda3/envs/advanced_ml/lib/python3.5/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/dexter/miniconda3/envs/advanced_ml/lib/python3.5/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/dexter/miniconda3/envs/advanced_ml/lib/python3.5/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/dexter/miniconda3/envs/advanced_ml/lib/python3.5/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-188-806ea78fd318>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m           \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m           \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m           epoch=epoch)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-185-69ff524fcf9b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, encoder, decoder, criterion, encoder_optimizer, decoder_optimizer, epoch)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;31m# Forward prop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaps_sorted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malphas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaplens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;31m# Since we decoded starting with <start>, the targets are all words after <start>, up to <end>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/advanced_ml/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Show-Attend-and-Tell-Pytorch-Implementation/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, encoder_out, encoded_captions, caption_lengths)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;31m# We won't decode at the <end> position, since we've finished generating as soon as we generate <end>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;31m# So, decoding lengths are actual lengths - 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0mdecode_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcaption_lengths\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Create tensors to hold word predicion scores and alphas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "# Epochs\n",
    "for epoch in range(start_epoch, epochs):\n",
    "\n",
    "    # Decay learning rate if there is no improvement for 8 consecutive epochs, and terminate training after 20\n",
    "    if epochs_since_improvement == 20:\n",
    "        break\n",
    "    if epochs_since_improvement > 0 and epochs_since_improvement % 8 == 0:\n",
    "        adjust_learning_rate(decoder_optimizer, 0.8)\n",
    "        if fine_tune_encoder:\n",
    "            adjust_learning_rate(encoder_optimizer, 0.8)\n",
    "'''         \n",
    "# One epoch's training\n",
    "train(train_datasets,\n",
    "      test_datasets,\n",
    "      encoder=encoder,\n",
    "      decoder=decoder,\n",
    "      epochs_per_task,\n",
    "      batch_size=64, test_size=1024, consolidate=True,\n",
    "      fisher_estimation_sample_size=1024,\n",
    "      lr=1e-3, weight_decay=1e-5,\n",
    "      loss_log_interval=30,\n",
    "      eval_log_interval=50,\n",
    "      cuda=False,\n",
    "      criterion=criterion,\n",
    "      encoder_optimizer=encoder_optimizer,\n",
    "      decoder_optimizer=decoder_optimizer,\n",
    "      epoch=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
